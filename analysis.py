import os
import numpy as np
import matplotlib.pyplot as plt
import re
import parasail
from bonito.util import parasail_to_sam

def get_error_summary(ref, read, is_seq=False):
    """
    Computes alignment between reference sequence and sequence provided. Assumes performing single
    sequence alignment.
    Parameters
    ----------
    ref : string
        Reference sequence
    read : string
        Read sequence
    is_seq : bool
        If True, ref and read are interpreted as raw sequences. Otherwise, they are interpreted as
        filenames for the reference and read sequence.
    Returns
    -------
    (ndarray(dtype=int), ndarray(dtype=int), ndarray(dtype=int), string, string):
        Positions of insertions, deletions, substitutions in sequence and alignment of ref and read.
    """
    if not is_seq:
        # Read from files
        with open(os.path.join(ref)) as ref_f:
            ref = ref_f.readlines()[1].strip()
        with open(os.path.join(read)) as read_f:
            read = read_f.readlines()[1].strip()

    error_summary = sm_align(ref, read)

    ref_align, read_align, _, ins_pos, dels_pos, subs_pos = error_summary
    ref_length = len(ref)
    ins_count = np.sum(ins_pos)
    dels_count = np.sum(dels_pos)
    subs_count = np.sum(subs_pos)
    print("Insertion errors %.3f%%, deletion errors %.3f%%, substitution errors %.3f%%, error rate %.3f%%"
        % (ins_count / ref_length * 100, dels_count / ref_length * 100, subs_count / ref_length * 100, (ins_count + dels_count + subs_count) / ref_length * 100))

    return ins_pos, dels_pos, subs_pos, ref_align, read_align


def get_errors(ref, read, is_seq=False):
    """
        Returns insertion, deletion, substitution and total error rates for reference and read sequences.
        Parameters
        ----------
        ref : string
            Reference sequence
        read : string
            Read sequence
        is_seq : bool
            If True, ref and read are interpreted as raw sequences. Otherwise, they are interpreted as
            filenames for the reference and read sequence.
        Returns
        -------
        (float, float, float, float):
            Insertion, deletion, substitution and total error rates.
    """
    if len(read) == 0:
        print("LOST SEQUENCE: ignoring errors")
        return 0, 0, 0, 0
    ins_pos, dels_pos, subs_pos, ref_align, read_align = get_error_summary(ref, read, is_seq)
    ref_length = len(ref)
    ins_count = np.sum(ins_pos)
    dels_count = np.sum(dels_pos)
    subs_count = np.sum(subs_pos)
    return ins_count / ref_length * 100, dels_count / ref_length * 100, subs_count / ref_length * 100, (ins_count + dels_count + subs_count) / ref_length * 100


def parasail_align(ref='ATTCAAGTTTCCGACCGCGC', read='CTCGTGTTCCGATCGC', is_seq=True):
    """
        TODO: switch to parasail alignment - much faster using vectorised operations.
        This is just some WIP code showing how to get the alignment and CIGAR string from the alignment of read and ref,
        but the output of this function needs to be computed to output the same as sm_align().
    """
    alignment = parasail.sw_trace_striped_32(read, ref, 8, 4, parasail.dnafull)
    rstart, cigar = parasail_to_sam(alignment, read)
    print(rstart)
    print(cigar)
    # TODO ending


# get_similarity_score and sm_align adapted from
# https://github.com/JiaShun-Xiao/BLAST-bioinfor-tool/blob/master/blast.py
# TODO: refactor
def get_similarity_score(a, b, match_score=1, mismatch_score=-1):
    if a == b:
        return 1
    else:
        return -1


# Smithâ€“Waterman Alignment
def sm_align(seq1, seq2, gap_penalty=3):
    """
        Computes Smith-Waterman alignment between two sequences.
        Returns
        -------
        (string, string, float, [int], [int], [int]):
            Tuple containing the produced alignment of seq1 and seq2 as strings, the alignment score computed,
            and the number of insertion, deletion and substitution errors taking place at each position of seq1.

        TODO: Bug when aligning the following two sequences:
        -------
        GTTTGGACAATCTCGGCGTGTTCTATTCTCTGGCCCGAATCGAGTCTGCCTACTACCTCTCGGCTCCTTTGCATACCTCAGAGAACGACCCCTATCCCTG
        C
        Insertion errors 0.000%, deletion errors 0.000%, substitution errors 0.000%, error rate 0.000%
    """
    m = len(seq1)
    n = len(seq2)
    ins_pos = np.zeros(m)
    dels_pos = np.zeros(m)
    subs_pos = np.zeros(m)
    g = -gap_penalty
    matrix = []
    for i in range(0, m):
        tmp = []
        for j in range(0, n):
            tmp.append(0)
        matrix.append(tmp)
    for sii in range(0, m):
        matrix[sii][0] = sii*g
    for sjj in range(0, n):
        matrix[0][sjj] = sjj*g
    for siii in range(1, m):
        for sjjj in range(1, n):
            matrix[siii][sjjj] = max(matrix[siii-1][sjjj] + g, matrix[siii - 1][sjjj - 1] + get_similarity_score(seq1[siii], seq2[sjjj]), matrix[siii][sjjj-1] + g)
    sequ1 = [seq1[m-1]]
    sequ2 = [seq2[n-1]]

    while m > 1 and n > 1:
        if max(matrix[m-1][n-2], matrix[m-2][n-2], matrix[m-2][n-1]) == matrix[m-2][n-2]:
            m -= 1
            n -= 1
            sequ1.append(seq1[m-1])
            sequ2.append(seq2[n-1])
            if seq1[m-1] != seq2[n-1]:
                # Subsitution
                subs_pos[m-1] +=1
        elif max(matrix[m-1][n-2], matrix[m-2][n-2], matrix[m-2][n-1]) == matrix[m-1][n-2]:
            # Insertion
            n -= 1
            sequ1.append('-')
            sequ2.append(seq2[n-1])
            ins_pos[m-2] += 1
        else:
            # Deletion
            m -= 1
            sequ1.append(seq1[m-1])
            sequ2.append('-')
            dels_pos[m-1] += 1
    sequ1.reverse()
    sequ2.reverse()
    align_seq1 = ''.join(sequ1)
    align_seq2 = ''.join(sequ2)
    align_score = 0.
    for k in range(0, len(align_seq1)):
        if align_seq1[k] == align_seq2[k]:
            align_score += 1
    align_score = float(align_score)/len(align_seq1)
    return align_seq1, align_seq2, align_score, ins_pos, dels_pos, subs_pos


def get_errors_from_file(filename, outdir='', limit=200):
    """
        Computes error statistics from a file containing entries of reads and reference sequences.
        The file must be formatted with each entry consisting of 3 lines: the id, reference sequence, and read sequence.
    """
    ins_pos = np.array([]) # relative
    dels_pos = np.array([]) # relative
    subs_pos = np.array([]) # relative
    ins_rates = []
    dels_rates = []
    subs_rates = []
    error_rates = []
    ref_lengths = []
    read_lengths = [] # relative
    with open(filename, 'r') as f:
        num_samples = 0
        line = f.readline()
        while line and num_samples < limit:
            ref = f.readline().strip()
            read = f.readline().strip()
            error_summary = sm_align(ref, read)
            ref_align, read_align, _, ins, dels, subs = error_summary
            with open(os.path.join(outdir, 'error_pos.log'), 'a') as log:
                log.write("%s\n%s\n%s\n" % (ins.tolist(), dels.tolist(), subs.tolist()))

            relative_pos = lambda x: x / len(ref)
            ins_rates.append(np.sum(ins) / len(ref) * 100)
            ins = [[i for j in range(int(err_count))] for i, err_count in enumerate(ins)]
            ins = [relative_pos(pos) for sublist in ins for pos in sublist]
            ins_pos = np.concatenate((ins_pos, ins))

            dels_rates.append(np.sum(dels) / len(ref) * 100)
            dels = [[i for j in range(int(err_count))] for i, err_count in enumerate(dels)]
            dels = [relative_pos(pos) for sublist in dels for pos in sublist]
            dels_pos = np.concatenate((dels_pos, dels))

            subs_rates.append(np.sum(subs) / len(ref) * 100)
            subs = [[i for j in range(int(err_count))] for i, err_count in enumerate(subs)]
            subs = [relative_pos(pos) for sublist in subs for pos in sublist]
            subs_pos = np.concatenate((subs_pos, subs))

            error_rates.append(ins_rates[-1] + dels_rates[-1] * subs_rates[-1])
            print("%s, %s, %s, %s" % (ins_rates[-1], dels_rates[-1], subs_rates[-1], ins_rates[-1] + dels_rates[-1] + subs_rates[-1]))

            ref_lengths.append(len(ref))
            read_lengths.append(len(read) / len(ref))

            line = f.readline()
            num_samples += 1

    ins_rate = np.mean(ins_rates)
    dels_rate = np.mean(dels_rates)
    subs_rate = np.mean(subs_rates)
    print("Average insertions %.3f%%, deletions %.3f%%, substitutions %.3f%%, errors %.3f%%"
        % (ins_rate, dels_rate, subs_rate, ins_rate + dels_rate + subs_rate))

    # Plotting distribution of insertion, deletion & substitution errors
    plt.figure()
    plt.title("Sequence Error Distribution")
    x, y = np.unique(ins_pos, return_counts=True)
    x, y = bucket_frequencies(x, y, 0, 1, 0.002)
    plt.plot(x, y, label="Insertions")
    x, y = np.unique(dels_pos, return_counts=True)
    x, y = bucket_frequencies(x, y, 0, 1, 0.002)
    plt.plot(x, y, label="Deletions")
    x, y = np.unique(subs_pos, return_counts=True)
    x, y = bucket_frequencies(x, y, 0, 1, 0.002)
    plt.plot(x, y, label="Substitutions")
    plt.xlabel('DNA Sequence Relative Position')
    plt.ylabel('Total Error Count')
    plt.legend()
    plt.savefig(os.path.join(outdir, "error_distribution.png"), dpi=800)

    # Write statistics
    with open(os.path.join(outdir, 'avg_error_summary.txt'), 'w') as fasta:
        fasta.write("Insertions(%%):\t\t%.3f\nDeletions(%%):\t\t\t%.3f\nSubstitutions(%%):\t%.3f\nErrors(%%):\t\t\t\t%.3f\n"
            % (ins_rate, dels_rate, subs_rate, (ins_rate + dels_rate + subs_rate)))

    # Plot read length vs error rate
    plt.figure()
    plt.title("Sequence Length vs Error Rate")
    plt.plot(ref_lengths, error_rates, 'o')
    plt.plot(np.unique(ref_lengths), np.poly1d(np.polyfit(ref_lengths, error_rates, 1))(np.unique(ref_lengths)))
    plt.xlabel('Sequence Length (nt)')
    plt.ylim(0,10)
    plt.ylabel('Error Rate (%)')
    plt.savefig(os.path.join(outdir, "len_vs_errors.png"), dpi=800)

    # Plot distribution of read lengths
    plt.figure()
    x, y = np.unique(read_lengths, return_counts=True)
    x, y = bucket_frequencies(x, y, 0.88, 1.12, 0.005)
    x, y = filter_zero_counts(x, y)
    plt.title("Relative Read Length Distribution")
    plt.scatter(x, y)
    plt.ylabel('Frequency')
    plt.xlabel('Relative Read Length')
    plt.axvline(x=1, label="Reference Length")
    plt.savefig(os.path.join(outdir, "read_len_distribution.png"), dpi=800)


def bucket_frequencies(x, y, lo, hi, interval):
    x_new = np.arange(lo + interval / 2, hi, interval)
    y_new = np.zeros(int((hi - lo) / interval))
    for i in range(len(x)):
        y_new[int((x[i] - lo) // interval)] += y[i]
    return x_new, y_new


def filter_zero_counts(x, y):
    x_new = []
    y_new = []
    for i in range(len(y)):
        if y[i] != 0:
            x_new.append(x[i])
            y_new.append(y[i])
    return x_new, y_new
